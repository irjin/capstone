{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809293ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ba1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6820c",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddeeddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>A viral Oct. 28 social media post claimed that...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>In 2016, Wisconsin helped to swing the preside...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  A viral Oct. 28 social media post claimed that...   \n",
       "1  In 2016, Wisconsin helped to swing the preside...   \n",
       "\n",
       "                                             summary  label  \n",
       "0  Haaretz, an Israeli newspaper, said on X that ...    4.0  \n",
       "1  Although Wisconsin has voted for more Democrat...    3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_dataset(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.drop(columns=[\"percentages\", \"check_nums\"]).drop_duplicates().dropna()\n",
    "    \n",
    "    mapping = {\n",
    "        \"true\": 0,\n",
    "        \"mostly-true\": 1,\n",
    "        \"half-true\": 2,\n",
    "        \"barely-true\": 3,\n",
    "        \"false\": 4,\n",
    "        \"pants-fire\": 5\n",
    "    }\n",
    "    \n",
    "    df[\"label\"] = df[\"label\"].map(mapping)\n",
    "    \n",
    "    df = df[pd.to_numeric(df[\"label\"], errors=\"coerce\").notna()]\n",
    "    df = df[[\"content\",\"article\",\"summaries\",\"label\"]]\n",
    "    df[\"content\"] = df[\"content\"].str.replace(r'[“\\”]', '', regex=True)\n",
    "    df[\"summaries\"] = df[\"summaries\"].str.replace(r'[\\[\\]\\'\"]', '', regex=True)\n",
    "    df.columns = [\"title\", \"article\", \"summary\", \"label\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_dataset(\"politifact_data_combined.csv\")\n",
    "df = df = df[df['summary'] != '']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15564649",
   "metadata": {},
   "source": [
    "### Feature 1: ClickBait (Cosine Similarity Between Title and Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the TF-IDF for title and article\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_title = tfidf_vectorizer.fit_transform(df[\"title\"])\n",
    "tfidf_article = tfidf_vectorizer.transform(df[\"article\"])\n",
    "\n",
    "\n",
    "# 2. Cosine Similarity\n",
    "\n",
    "cosine = cosine_similarity(tfidf_title, tfidf_article)\n",
    "cosine_sim = cosine.diagonal()\n",
    "\n",
    "df[\"similarity\"] = cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6337da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom labels\n",
    "\n",
    "def feature_mapping(value):\n",
    "    if value <= (min_val + interval):\n",
    "        return 0\n",
    "    elif value <= (min_val + 2 * interval):\n",
    "        return 1\n",
    "    elif value <= (min_val + 3 * interval):\n",
    "        return 2\n",
    "    elif value <= (min_val + 4 * interval):\n",
    "        return 3\n",
    "    elif value <= (min_val + 5 * interval):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# min_val, max_val = df[\"similarity\"].min(), df[\"similarity\"].max()\n",
    "# interval = (max_val - min_val) / 6\n",
    "\n",
    "# df[\"similarity\"] = df[\"similarity\"].apply(feature_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257f032",
   "metadata": {},
   "source": [
    "### Feature 2: Sentiment Analysis  (pos=1, neg=-1, neu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289c8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sentiment Analysis Using NLTK\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df[\"sentiment\"] = df[\"article\"].apply(lambda x: analyzer.polarity_scores(x)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34db9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom labels\n",
    "\n",
    "# min_val, max_val = df['sentiment'].min(), df['sentiment'].max()\n",
    "# interval = (max_val - min_val) / 6\n",
    "\n",
    "# df['sentiment'] = df['sentiment'].apply(feature_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263adf1",
   "metadata": {},
   "source": [
    "### Feature 3: Quality of Writing (Type-Token Ratio (TTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d3944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove stopwords and punctuation & Make lowercase\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [w for w in words if w not in stopwords]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = ''.join([char for char in text if char not in punctuation])\n",
    "    return cleaned_text\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(lambda x: x.lower())\n",
    "df[\"article\"] = df[\"article\"].apply(remove_punctuation)\n",
    "df[\"article\"] = df[\"article\"].apply(remove_stopwords)\n",
    "\n",
    "# 2. TTR = unique_words/total_words\n",
    "\n",
    "df['ttr'] = df['article'].apply(lambda x: x.split()).apply(lambda words: len(set(words)) / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a986a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_val, max_val = df['ttr'].min(), df['ttr'].max()\n",
    "# interval = (max_val - min_val) / 6\n",
    "\n",
    "# df['ttr'] = df['ttr'].apply(feature_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56c613",
   "metadata": {},
   "source": [
    "### Feature 4: Expressiveness (Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b24dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Open List of Adjectives (Link: https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913)\n",
    "    ### Additional Sources: https://github.com/taikuukaits/SimpleWordlists/tree/master\n",
    "\n",
    "with open(\"adjectives.txt\", \"r\") as file:\n",
    "    adjectives = [line.strip() for line in file]\n",
    "    \n",
    "# 2. Count adjectives\n",
    "\n",
    "def count_adjectives(text):\n",
    "    words = text.split()\n",
    "    adjective_count = sum(1 for word in words if word.lower() in adjectives) / len(words)\n",
    "    return adjective_count\n",
    "\n",
    "df[\"adjectives\"] = df[\"article\"].apply(count_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cbcf9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_val, max_val = df[\"adjectives\"].min(), df[\"adjectives\"].max()\n",
    "# interval = (max_val - min_val) / 6\n",
    "\n",
    "# df[\"adjectives\"] = df[\"adjectives\"].apply(feature_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b527c9",
   "metadata": {},
   "source": [
    "### SMOTE + Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2d26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ttr</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>viral oct 28 social media post claimed israel ...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.457559</td>\n",
       "      <td>-0.9994</td>\n",
       "      <td>0.593137</td>\n",
       "      <td>0.031863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>2016 wisconsin helped swing presidential vote ...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.358756</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.640472</td>\n",
       "      <td>0.098232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  viral oct 28 social media post claimed israel ...   \n",
       "1  2016 wisconsin helped swing presidential vote ...   \n",
       "\n",
       "                                             summary  label  similarity  \\\n",
       "0  Haaretz, an Israeli newspaper, said on X that ...    4.0    0.457559   \n",
       "1  Although Wisconsin has voted for more Democrat...    3.0    0.358756   \n",
       "\n",
       "   sentiment       ttr  adjectives  \n",
       "0    -0.9994  0.593137    0.031863  \n",
       "1     0.9919  0.640472    0.098232  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd45b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Points for Label 0 is 178\n",
      "This is 0.030308190022135195 of the entire dataset \n",
      "\n",
      "Number of Data Points for Label 1 is 314\n",
      "This is 0.053465009364890174 of the entire dataset \n",
      "\n",
      "Number of Data Points for Label 2 is 440\n",
      "This is 0.07491912140303082 of the entire dataset \n",
      "\n",
      "Number of Data Points for Label 3 is 720\n",
      "This is 0.12259492593223224 of the entire dataset \n",
      "\n",
      "Number of Data Points for Label 4 is 3159\n",
      "This is 0.537885237527669 of the entire dataset \n",
      "\n",
      "Number of Data Points for Label 5 is 1062\n",
      "This is 0.18082751575004258 of the entire dataset \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Distribution of labels -> Requires Oversampling later\n",
    "\n",
    "for i in range(0,6):\n",
    "    print(\"Number of Data Points for Label \" + str(i) + \" is \"+ str(len(df[df[\"label\"]==i])))\n",
    "    print(\"This is \" + str(len(df[df[\"label\"]==i]) / len(df)) + \" of the entire dataset \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b8e1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling\n",
    "\n",
    "X = df.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "smote = SMOTE(sampling_strategy={0: 400, 1: 500, 2: 500, 3: 800, 4: 3159, 5: 1062}, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72106e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test_multi = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac473d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.73      0.51        82\n",
      "         1.0       0.22      0.37      0.27        94\n",
      "         2.0       0.23      0.27      0.25        91\n",
      "         3.0       0.24      0.21      0.22       145\n",
      "         4.0       0.59      0.56      0.57       651\n",
      "         5.0       0.34      0.19      0.24       222\n",
      "\n",
      "    accuracy                           0.43      1285\n",
      "   macro avg       0.33      0.39      0.34      1285\n",
      "weighted avg       0.44      0.43      0.43      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.04      0.07        82\n",
      "         1.0       0.12      0.01      0.02        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.14      0.06      0.09       145\n",
      "         4.0       0.52      0.91      0.66       651\n",
      "         5.0       0.41      0.10      0.16       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.27      0.19      0.17      1285\n",
      "weighted avg       0.38      0.49      0.38      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.01      0.02        82\n",
      "         1.0       0.15      0.02      0.04        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.15      0.02      0.04       145\n",
      "         4.0       0.51      0.97      0.67       651\n",
      "         5.0       0.40      0.01      0.02       222\n",
      "\n",
      "    accuracy                           0.50      1285\n",
      "   macro avg       0.29      0.17      0.13      1285\n",
      "weighted avg       0.39      0.50      0.35      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.19      0.02      0.04       145\n",
      "         4.0       0.51      0.99      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.50      1285\n",
      "   macro avg       0.12      0.17      0.12      1285\n",
      "weighted avg       0.28      0.50      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.04      0.06        82\n",
      "         1.0       0.22      0.15      0.18        94\n",
      "         2.0       0.09      0.02      0.04        91\n",
      "         3.0       0.21      0.06      0.10       145\n",
      "         4.0       0.53      0.87      0.66       651\n",
      "         5.0       0.43      0.12      0.18       222\n",
      "\n",
      "    accuracy                           0.48      1285\n",
      "   macro avg       0.27      0.21      0.20      1285\n",
      "weighted avg       0.40      0.48      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.04      0.06        82\n",
      "         1.0       0.12      0.02      0.04        94\n",
      "         2.0       0.22      0.02      0.04        91\n",
      "         3.0       0.17      0.12      0.14       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.49      0.09      0.15       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.30      0.20      0.18      1285\n",
      "weighted avg       0.41      0.49      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.09      0.13        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.25      0.01      0.02        91\n",
      "         3.0       0.17      0.13      0.15       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.47      0.06      0.11       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.28      0.20      0.18      1285\n",
      "weighted avg       0.40      0.49      0.38      1285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = classifier.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd12a5",
   "metadata": {},
   "source": [
    "#### Predictions (One vs One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56d056a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.73      0.51        82\n",
      "         1.0       0.22      0.37      0.27        94\n",
      "         2.0       0.23      0.27      0.25        91\n",
      "         3.0       0.24      0.21      0.22       145\n",
      "         4.0       0.59      0.56      0.57       651\n",
      "         5.0       0.34      0.19      0.24       222\n",
      "\n",
      "    accuracy                           0.43      1285\n",
      "   macro avg       0.33      0.39      0.34      1285\n",
      "weighted avg       0.44      0.43      0.43      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.04      0.07        82\n",
      "         1.0       0.12      0.01      0.02        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.14      0.06      0.09       145\n",
      "         4.0       0.52      0.91      0.66       651\n",
      "         5.0       0.41      0.10      0.16       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.27      0.19      0.17      1285\n",
      "weighted avg       0.38      0.49      0.38      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.02      0.05        82\n",
      "         1.0       0.20      0.01      0.02        94\n",
      "         2.0       1.00      0.01      0.02        91\n",
      "         3.0       0.17      0.03      0.05       145\n",
      "         4.0       0.51      0.98      0.67       651\n",
      "         5.0       0.67      0.02      0.04       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.51      0.18      0.14      1285\n",
      "weighted avg       0.51      0.51      0.36      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.09      0.01      0.01       145\n",
      "         4.0       0.51      0.99      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.50      1285\n",
      "   macro avg       0.10      0.17      0.11      1285\n",
      "weighted avg       0.27      0.50      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.04      0.06        82\n",
      "         1.0       0.22      0.15      0.18        94\n",
      "         2.0       0.09      0.02      0.04        91\n",
      "         3.0       0.21      0.06      0.10       145\n",
      "         4.0       0.53      0.87      0.66       651\n",
      "         5.0       0.43      0.12      0.18       222\n",
      "\n",
      "    accuracy                           0.48      1285\n",
      "   macro avg       0.27      0.21      0.20      1285\n",
      "weighted avg       0.40      0.48      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.04      0.06        82\n",
      "         1.0       0.12      0.02      0.04        94\n",
      "         2.0       0.22      0.02      0.04        91\n",
      "         3.0       0.17      0.12      0.14       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.49      0.09      0.15       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.30      0.20      0.18      1285\n",
      "weighted avg       0.41      0.49      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.09      0.13        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.25      0.01      0.02        91\n",
      "         3.0       0.17      0.13      0.15       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.47      0.06      0.11       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.28      0.20      0.18      1285\n",
      "weighted avg       0.40      0.49      0.38      1285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = classifier.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2848a",
   "metadata": {},
   "source": [
    "#### Predictions (One vs Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28336466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.39      0.73      0.51        82\n",
      "         1.0       0.22      0.37      0.27        94\n",
      "         2.0       0.23      0.27      0.25        91\n",
      "         3.0       0.24      0.21      0.22       145\n",
      "         4.0       0.59      0.56      0.57       651\n",
      "         5.0       0.34      0.19      0.24       222\n",
      "\n",
      "    accuracy                           0.43      1285\n",
      "   macro avg       0.33      0.39      0.34      1285\n",
      "weighted avg       0.44      0.43      0.43      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.00      0.00      0.00       145\n",
      "         4.0       0.51      1.00      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.08      0.17      0.11      1285\n",
      "weighted avg       0.26      0.51      0.34      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.04      0.07        82\n",
      "         1.0       0.12      0.01      0.02        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.14      0.06      0.09       145\n",
      "         4.0       0.52      0.91      0.66       651\n",
      "         5.0       0.41      0.10      0.16       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.27      0.19      0.17      1285\n",
      "weighted avg       0.38      0.49      0.38      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       1.00      0.01      0.02        91\n",
      "         3.0       0.29      0.04      0.07       145\n",
      "         4.0       0.51      0.98      0.67       651\n",
      "         5.0       0.44      0.02      0.03       222\n",
      "\n",
      "    accuracy                           0.51      1285\n",
      "   macro avg       0.54      0.18      0.14      1285\n",
      "weighted avg       0.50      0.51      0.36      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.00      0.00      0.00        91\n",
      "         3.0       0.20      0.03      0.06       145\n",
      "         4.0       0.51      0.98      0.67       651\n",
      "         5.0       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.50      1285\n",
      "   macro avg       0.12      0.17      0.12      1285\n",
      "weighted avg       0.28      0.50      0.35      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.04      0.06        82\n",
      "         1.0       0.22      0.15      0.18        94\n",
      "         2.0       0.09      0.02      0.04        91\n",
      "         3.0       0.21      0.06      0.10       145\n",
      "         4.0       0.53      0.87      0.66       651\n",
      "         5.0       0.43      0.12      0.18       222\n",
      "\n",
      "    accuracy                           0.48      1285\n",
      "   macro avg       0.27      0.21      0.20      1285\n",
      "weighted avg       0.40      0.48      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.04      0.06        82\n",
      "         1.0       0.12      0.02      0.04        94\n",
      "         2.0       0.22      0.02      0.04        91\n",
      "         3.0       0.17      0.12      0.14       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.49      0.09      0.15       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.30      0.20      0.18      1285\n",
      "weighted avg       0.41      0.49      0.39      1285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.09      0.13        82\n",
      "         1.0       0.00      0.00      0.00        94\n",
      "         2.0       0.25      0.01      0.02        91\n",
      "         3.0       0.17      0.13      0.15       145\n",
      "         4.0       0.53      0.90      0.67       651\n",
      "         5.0       0.47      0.06      0.11       222\n",
      "\n",
      "    accuracy                           0.49      1285\n",
      "   macro avg       0.28      0.20      0.18      1285\n",
      "weighted avg       0.40      0.49      0.38      1285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = classifier.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f2553",
   "metadata": {},
   "source": [
    "### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24063ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.91      0.84       608\n",
      "         1.0       0.77      0.87      0.81       632\n",
      "         2.0       0.73      0.86      0.79       588\n",
      "         3.0       0.72      0.76      0.74       592\n",
      "         4.0       0.69      0.29      0.40       625\n",
      "         5.0       0.69      0.75      0.72       587\n",
      "\n",
      "    accuracy                           0.74      3632\n",
      "   macro avg       0.73      0.74      0.72      3632\n",
      "weighted avg       0.73      0.74      0.72      3632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN & increased samples in SMOTE for Minority Class\n",
    "\n",
    "X = df.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "smote = SMOTE(sampling_strategy={0: 3000, 1: 3000, 2: 3000, 3: 3000, 4: 3159, 5: 3000}, random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_multi = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(3).fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test_multi, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc25b1",
   "metadata": {},
   "source": [
    "### Predictions (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1dd93ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ttr</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haaretz investigation reveals discrepancies in...</td>\n",
       "      <td>viral oct 28 social media post claimed israel ...</td>\n",
       "      <td>Haaretz, an Israeli newspaper, said on X that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457559</td>\n",
       "      <td>-0.9994</td>\n",
       "      <td>0.593137</td>\n",
       "      <td>0.031863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin has historically … and I think large...</td>\n",
       "      <td>2016 wisconsin helped swing presidential vote ...</td>\n",
       "      <td>Although Wisconsin has voted for more Democrat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358756</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.640472</td>\n",
       "      <td>0.098232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Haaretz investigation reveals discrepancies in...   \n",
       "1  Wisconsin has historically … and I think large...   \n",
       "\n",
       "                                             article  \\\n",
       "0  viral oct 28 social media post claimed israel ...   \n",
       "1  2016 wisconsin helped swing presidential vote ...   \n",
       "\n",
       "                                             summary  label  similarity  \\\n",
       "0  Haaretz, an Israeli newspaper, said on X that ...      1    0.457559   \n",
       "1  Although Wisconsin has voted for more Democrat...      1    0.358756   \n",
       "\n",
       "   sentiment       ttr  adjectives  \n",
       "0    -0.9994  0.593137    0.031863  \n",
       "1     0.9919  0.640472    0.098232  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary = df.copy()\n",
    "\n",
    "def binary_map(val):\n",
    "    if val in [0, 1, 2]:\n",
    "        return 0\n",
    "    elif val in [3, 4, 5]:\n",
    "        return 1\n",
    "\n",
    "df_binary['label'] = df_binary['label'].apply(binary_map)\n",
    "\n",
    "df_binary.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4020a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_binary.drop(columns=[\"title\",\"article\",\"summary\",\"label\"])\n",
    "y = df_binary[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test_binary = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7246268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Best --> Classifier = Random Forest, Score (test, accuracy) = 83.40\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    AdaBoostClassifier()]\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "max_score = 0.0\n",
    "max_class = ''\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = 100.0 * clf.score(X_test, y_test_binary)\n",
    "\n",
    "    if score > max_score:\n",
    "        clf_best = clf\n",
    "        max_score = score\n",
    "        max_class = name\n",
    "\n",
    "print(80*'-' )\n",
    "print('Best --> Classifier = %s, Score (test, accuracy) = %.2f' %(max_class, max_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
